{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac",
   "metadata": {
    "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac"
   },
   "source": [
    "# Assignment: Linear Models\n",
    "## Foundations of Machine Learning\n",
    "## Do Q1 and one other question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4826b0",
   "metadata": {
    "id": "bf4826b0"
   },
   "source": [
    "**Q0.** Please answer the following questions in your own words.\n",
    "\n",
    "1. What makes a model \"linear\"? \"Linear\" in what?\n",
    "2. How do you interpret the coefficient for a dummy/one-hot-encoded variable? (This is a trick question, and the trick involves how you handle the intercept of the model.)\n",
    "3. Can linear regression be used for classification? Explain why, or why not.\n",
    "4. What are signs that your linear model is over-fitting?\n",
    "5. Clearly explain multi-colinearity using the two-stage least squares technique.\n",
    "6. What are two ways to incorporate nonlinear relationships between your target/response/dependent/outcome variable $y$ and your features/control/response/independent variables $x$?\n",
    "7. What is the interpretation of the intercept? A slope coefficient for a variable? The coefficient for a dummy/one-hot-encoded variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874273ad",
   "metadata": {},
   "source": [
    "a.) A model is linear in that the data points are plotted on a 2D plane. In turn, this means that a model is linear in that its prediction is based off that 2D plane, even if it includes more than two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e2926",
   "metadata": {},
   "source": [
    "b.) The coefficent for a one-hot encoded variable is related to the magnitude and direction of the categorical variables impact on the regression model. If a categorical variable has a high positive value, then this means that a record with a true value for that categorical variable is associated with a higher target value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd4c67",
   "metadata": {},
   "source": [
    "c.) Yes, linear regression can be used for classification through the use of dummy variables. However, this can lead to conclusions that have severe interpretability issues. This can be due to uneven counts of classes, heteroskedasticity, and other potential problems with converting categorical data to a numerical regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3dcfe",
   "metadata": {},
   "source": [
    "d.) One of the easiest signs that a model is overfitting is that it performs incredibly well/accurately on the training data, but begins to falter on the test data. Demonstrating that the model is simply memorizing the test data instead of actually learning how to predict from the training data. Furthermore, a key sign of overfitting is a high variance, meaning that it has picked up too much of the irrelevant information from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151eae80",
   "metadata": {},
   "source": [
    "e.) Multi-collinearity refers to the case where multiple of the variables in the model interact with each other in a way that affects the interpretability of their correlation coefficients in the model. To help combat this, the two stage least squares technique regresses the endogenous variable on the IVs, obtain the predicted values from this regression, then regress the DV on these predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a61d2",
   "metadata": {},
   "source": [
    "f.) Two things that you can do to incorprate nonlinear relationships between your y and x would be polynomial regression and data transformations. In terms of a polynomial relationship, for example x squared, this relationship will not be linear because it will be a quadratic relationship between the two. In terms of data transformations, one could take the log of a variable in order to change its relationship with the target from linear to a logarthmic relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8dccb4",
   "metadata": {},
   "source": [
    "g.) The intercept of a linear regression model refers to the value of the target variable when all of the x variables are equal to zero. The slope coefficient of an x variable refers to the change in the predicted value of the target variable when the x variable changes by a value of 1, or 1% in terms of a log x variable. Lastly, the coefficient for a one hot encoded variable refers to the change in the target variable when the one-hot encoded variable is 1(essentially when the categorical variable is true)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d",
   "metadata": {
    "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d"
   },
   "source": [
    "**Q1.** Load `./data/Q1_clean.csv`. The data include\n",
    "\n",
    "- `Price` per night\n",
    "- `Review Scores Rating`: The average rating for the property\n",
    "- `Neighbourhood `: The bourough of NYC. Note the space, or rename the variable.\n",
    "- `Property Type`: The kind of dwelling\n",
    "- `Room Type`: The kind of space being rented\n",
    "\n",
    "1. Compute the average prices and scores by `Neighbourhood `; which bourough is the most expensive on average? Create a kernel density plot of price and log price, grouping by `Neighbourhood `.\n",
    "2. Regress price on `Neighbourhood ` by creating the appropriate dummy/one-hot-encoded variables, without an intercept in the linear model and using all the data. Compare the coefficients in the regression to the table from part 1. What pattern do you see? What are the coefficients in a regression of a continuous variable on one categorical variable?\n",
    "3. Repeat part 2, but leave an intercept in the linear model. How do you have to handle the creation of the dummies differently? What is the intercept? Interpret the coefficients. How can I get the coefficients in part 2 from these new coefficients?\n",
    "4. Split the sample 80/20 into a training and a test set. Run a regression of `Price` on `Review Scores Rating` and `Neighbourhood `. What is the $R^2$ and RMSE on the test set? What is the coefficient on `Review Scores Rating`? What is the most expensive kind of property you can rent?\n",
    "5. Split the sample 80/20 into a training and a test set. Run a regression of `Price` on `Review Scores Rating` and `Neighbourhood ` and `Property Type`. What is the $R^2$ and RMSE on the test set? What is the coefficient on `Review Scores Rating`? What is the most expensive kind of property you can rent?\n",
    "6. What does the coefficient on `Review Scores Rating` mean if it changes from part 4 to 5? Hint: Think about how multilple linear regression works.\n",
    "7. (Optional) We've included `Neighborhood ` and `Property Type` separately in the model. How do you interact them, so you can have \"A bedroom in Queens\" or \"A townhouse in Manhattan\". Split the sample 80/20 into a training and a test set and run a regression including that kind of \"property type X neighborhood\" dummy, plus `Review Scores Rating`. How does the slope coefficient for `Review Scores Rating`, the $R^2$, and the RMSE change? Do they increase significantly compares to part 5? Are the coefficients in this regression just the sum of the coefficients for `Neighbourhood ` and `Property Type` from 5? What is the most expensive kind of property you can rent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8471a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0efa8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'linearRegression' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jjordan4234/linearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "995dfe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1_clean.csv           cars_hw.csv            wages_hw.csv\r\n",
      "USA_cars_datasets.csv  \u001b[34mheart_failure\u001b[m\u001b[m/\r\n",
      "airbnb_hw.csv          pretrial_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls linearRegression/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e708377",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_clean = pd.read_csv('./linearRegression/data/Q1_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "630c1ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Review Scores Rating</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Room Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22148</th>\n",
       "      <td>90</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22149</th>\n",
       "      <td>65</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22150</th>\n",
       "      <td>55</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Loft</td>\n",
       "      <td>Shared room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22151</th>\n",
       "      <td>60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22152</th>\n",
       "      <td>99</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price  Review Scores Rating Neighbourhood  Property Type  \\\n",
       "0        549                  96.0      Manhattan     Apartment   \n",
       "1        149                 100.0       Brooklyn     Apartment   \n",
       "2        250                 100.0      Manhattan     Apartment   \n",
       "3         90                  94.0       Brooklyn     Apartment   \n",
       "4        270                  90.0      Manhattan     Apartment   \n",
       "...      ...                   ...            ...           ...   \n",
       "22148     90                 100.0      Manhattan     Apartment   \n",
       "22149     65                  80.0       Brooklyn     Apartment   \n",
       "22150     55                 100.0       Brooklyn          Loft   \n",
       "22151     60                 100.0       Brooklyn     Apartment   \n",
       "22152     99                  80.0      Manhattan     Apartment   \n",
       "\n",
       "             Room Type  \n",
       "0         Private room  \n",
       "1      Entire home/apt  \n",
       "2      Entire home/apt  \n",
       "3         Private room  \n",
       "4      Entire home/apt  \n",
       "...                ...  \n",
       "22148  Entire home/apt  \n",
       "22149     Private room  \n",
       "22150      Shared room  \n",
       "22151     Private room  \n",
       "22152     Private room  \n",
       "\n",
       "[22153 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b8896e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Price', 'Review Scores Rating', 'Neighbourhood ', 'Property Type',\n",
      "       'Room Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Q1_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8a2d56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bouroughs = Q1_clean['Neighbourhood '].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71168207",
   "metadata": {},
   "source": [
    "1.) Compute the average prices and scores by Neighbourhood; which bourough is the most expensive on average? Create a kernel density plot of price and log price, grouping by Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3f97ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg (df):\n",
    "    for bourough in bouroughs:\n",
    "        bourough_df = df[df['Neighbourhood '] == bourough]\n",
    "        \n",
    "        price = bourough_df['Price'].mean()\n",
    "        score = bourough_df['Review Scores Rating'].mean()\n",
    "        \n",
    "        print(f\"The average price for {bourough} is ${price:.2f} and its average score is {score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "322677a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average price for Manhattan is $183.66 and its average score is 91.80%\n",
      "The average price for Brooklyn is $127.75 and its average score is 92.36%\n",
      "The average price for Queens is $96.86 and its average score is 91.55%\n",
      "The average price for Bronx is $75.28 and its average score is 91.65%\n",
      "The average price for Staten Island is $146.17 and its average score is 90.84%\n",
      "The most expensive bourough on average is Manhattan.\n"
     ]
    }
   ],
   "source": [
    "avg (Q1_clean)\n",
    "print(\"The most expensive bourough on average is Manhattan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "638e6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the variable log price\n",
    "Q1_clean['log_price'] =  np.log(Q1_clean['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c8ef778",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-1bba26afc1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ1_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ1_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Neighbourhood '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ1_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ1_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Neighbourhood '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[0;34m(x, y, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, weights, hue, palette, hue_order, hue_norm, multiple, common_norm, common_grid, levels, thresh, bw_method, bw_adjust, log_scale, color, fill, data, data2, **kwargs)\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mplot_kws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1728\u001b[0;31m         p.plot_univariate_density(\n\u001b[0m\u001b[1;32m   1729\u001b[0m             \u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0mcommon_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mplot_univariate_density\u001b[0;34m(self, multiple, common_norm, common_grid, fill, legend, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     )\n\u001b[1;32m    995\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                     \u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0martist_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msticky_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                     message='Support for multi-dimensional indexing')\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m                 \u001b[0;31m# we have definitely hit a pandas index or series object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;31m# cast to a numpy array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5197\u001b[0m         \u001b[0;31m# Because we ruled out integer above, we always get an arraylike here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5199\u001b[0;31m             \u001b[0mdisallow_ndim_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5201\u001b[0m         \u001b[0;31m# NB: Using _constructor._simple_new would break if MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mdisallow_ndim_indexing\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0;34m\"Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;34m\"supported. Convert to a numpy array before indexing instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(x=Q1_clean['Price'], hue=Q1_clean['Neighbourhood '])\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(x=Q1_clean['log_price'], hue=Q1_clean['Neighbourhood '])\n",
    "plt.show()\n",
    "#I don't understand why this doesn't work ... I have tried everything (even tried the normal solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e62d2",
   "metadata": {},
   "source": [
    "2.) Regress price on Neighbourhood by creating the appropriate dummy/one-hot-encoded variables, without an intercept in the linear model and using all the data. Compare the coefficients in the regression to the table from part 1. What pattern do you see? What are the coefficients in a regression of a continuous variable on one categorical variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1b224f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Q1_clean['Price']\n",
    "x = pd.get_dummies(Q1_clean['Neighbourhood '], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "affeb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression(fit_intercept=False).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b5bb4cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>75.276498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>127.747378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>183.664286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queens</td>\n",
       "      <td>96.857233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staten Island</td>\n",
       "      <td>146.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable  coefficient\n",
       "0          Bronx    75.276498\n",
       "1       Brooklyn   127.747378\n",
       "2      Manhattan   183.664286\n",
       "3         Queens    96.857233\n",
       "4  Staten Island   146.166667"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'variable': x.columns, 'coefficient': reg.coef_})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5db9e3",
   "metadata": {},
   "source": [
    "One thing that I noticed were that the regression coefficients were the same as the mean prices in part one. This is because we are only regressing on one variable with no controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aee578",
   "metadata": {},
   "source": [
    "3.) Repeat part 2, but leave an intercept in the linear model. How do you have to handle the creation of the dummies differently? What is the intercept? Interpret the coefficients. How can I get the coefficients in part 2 from these new coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6d8aceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Q1_clean['Price']\n",
    "x = pd.get_dummies(Q1_clean['Neighbourhood '], dtype='int', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c0b5bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression(fit_intercept=True).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e0cff73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 52.47088065 108.38778863  21.58073501  70.89016897]\n"
     ]
    }
   ],
   "source": [
    "#results = pd.DataFrame({'variable': reg.feature_names_in_, 'coefficient': reg.coef_})\n",
    "#results\n",
    "#have spent a long time on this and can not get that to work, also what worked with x.columns previously no long\n",
    "print(reg.coef_)\n",
    "'''\n",
    "This was all I could do to get the coefficients to print out... Obviously not optimal but I don;t know why it wasn't\n",
    "working and this was the only way I could get the coefficients to show.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19fd47cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.27649769585157\n"
     ]
    }
   ],
   "source": [
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef0178c",
   "metadata": {},
   "source": [
    "To get the new coefficients from the answers in part 2 you just subtract the intercept from the previous regression coeffecients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7952cc4",
   "metadata": {},
   "source": [
    "4.) Split the sample 80/20 into a training and a test set. Run a regression of Price on Review Scores Rating and Neighbourhood. What is the  𝑅2\n",
    "  and RMSE on the test set? What is the coefficient on Review Scores Rating? What is the most expensive kind of property you can rent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11bf3f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Q1_clean['Price']\n",
    "x = Q1_clean.loc[:,['Review Scores Rating', 'Neighbourhood '] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "47a4aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f9198b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = pd.concat([x_train['Review Scores Rating'], \n",
    "                     pd.get_dummies(x_train['Neighbourhood '], dtype='int')], axis = 1)\n",
    "z_test = pd.concat([x_test['Review Scores Rating'], \n",
    "                    pd.get_dummies(x_test['Neighbourhood '], dtype='int')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "20d85e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression(fit_intercept=False).fit(z_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "af286b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq:  0.06701086106947296\n",
      "RMSE:  125.01092061382933\n"
     ]
    }
   ],
   "source": [
    "y_hat = reg.predict(z_test)\n",
    "print('Rsq: ', reg.score(z_test,y_test)) # R2\n",
    "rmse = np.sqrt( np.mean( (y_test - y_hat)**2 ))\n",
    "print('RMSE: ', rmse) # R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "53e46e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.62691227 -31.866502    -8.46528163  34.84956649 -25.6770672\n",
      "  31.15928434  79.21159104 -28.3048881  -50.90670294]\n"
     ]
    }
   ],
   "source": [
    "reg.fit(z_train,y_train)\n",
    "#results = pd.DataFrame({'variable': x.columns, 'coefficient': reg.coef_})\n",
    "#results\n",
    "#again the other way didn't work so I tried the x.columns and it didn't work either... still not sure why\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd7f05",
   "metadata": {},
   "source": [
    "The most expensive property that you could buy would be an apartment in Manhattan with a 100 rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eebfaa",
   "metadata": {},
   "source": [
    "5.) Split the sample 80/20 into a training and a test set. Run a regression of Price on Review Scores Rating and Neighbourhood and Property Type. What is the  𝑅2\n",
    "  and RMSE on the test set? What is the coefficient on Review Scores Rating? What is the most expensive kind of property you can rent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b29bc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Q1_clean['Price']\n",
    "x = Q1_clean.loc[:,['Review Scores Rating', 'Neighbourhood ', 'Room Type'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "30a159bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b7cd939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = pd.concat([x_train['Review Scores Rating'], \n",
    "                    pd.get_dummies(x_train['Neighbourhood '], dtype='int'),\n",
    "                    pd.get_dummies(x_train['Room Type'], dtype='int')],\n",
    "                    axis = 1)\n",
    "z_test = pd.concat([x_test['Review Scores Rating'], \n",
    "                    pd.get_dummies(x_test['Neighbourhood '], dtype='int'),\n",
    "                    pd.get_dummies(x_test['Room Type'], dtype='int')],\n",
    "                    axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "81a412fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression(fit_intercept=False).fit(Z_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "83d5fb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq:  0.22035348129282328\n",
      "RMSE:  114.27692123130632\n"
     ]
    }
   ],
   "source": [
    "y_hat = reg.predict(z_test)\n",
    "print('Rsq: ', reg.score(z_test,y_test))\n",
    "rmse = np.sqrt( np.mean( (y_test - y_hat)**2 ))\n",
    "print('RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "82dae7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.62691227 -31.866502    -8.46528163  34.84956649 -25.6770672\n",
      "  31.15928434  79.21159104 -28.3048881  -50.90670294]\n"
     ]
    }
   ],
   "source": [
    "#results = pd.DataFrame({'variable':reg.feature_names_in_, 'coefficient': reg.coef_})\n",
    "#results\n",
    "#again, anything I do doesn't fix it\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cc525",
   "metadata": {},
   "source": [
    "In this case, Manhattan is still the neighbourhood with the highest prices, but the highest price is for an entire home/appartment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4e422",
   "metadata": {},
   "source": [
    "6.) What does the coefficient on Review Scores Rating mean if it changes from part 4 to 5? Hint: Think about how multilple linear regression works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c140226",
   "metadata": {},
   "source": [
    "While I have been unable to see some of the coeffecients because of a problem with how the code works, I will make some assumptions based on basic multiple linear regression principles. I would assume that the two coefficients will change because the first regression coefficient does not control for the room type changing across different apartments. Therefore, when the variable is added into the multiple regression, I would guess that the coefficeint of Review Scores Rating will drop because the Room Type will have some predictive ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b",
   "metadata": {
    "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b"
   },
   "source": [
    "**Q2.** This question is a case study for linear models. The data are about car prices. In particular, they include:\n",
    "\n",
    "  - `Price`, `Color`, `Seating_Capacity`\n",
    "  - `Body_Type`: crossover, hatchback, muv, sedan, suv\n",
    "  - `Make`, `Make_Year`: The brand of car and year produced\n",
    "  - `Mileage_Run`: The number of miles on the odometer\n",
    "  - `Fuel_Type`: Diesel or gasoline/petrol\n",
    "  - `Transmission`, `Transmission_Type`:  speeds and automatic/manual\n",
    "\n",
    "  1. Load `cars_hw.csv`. These data were really dirty, and I've already cleaned them a significant amount in terms of missing values and other issues, but some issues remain (e.g. outliers, badly scaled variables that require a log or arcsinh transformation). Clean the data however you think is most appropriate.\n",
    "  2. Summarize the `Price` variable and create a kernel density plot. Use `.groupby()` and `.describe()` to summarize prices by brand (`Make`). Make a grouped kernel density plot by `Make`. Which car brands are the most expensive? What do prices look like in general?\n",
    "  3. Split the data into an 80% training set and a 20% testing set.\n",
    "  4. Make a model where you regress price on the numeric variables alone; what is the $R^2$ and `RMSE` on the training set and test set? Make a second model where, for the categorical variables, you regress price on a model comprised of one-hot encoded regressors/features alone (you can use `pd.get_dummies()`; be careful of the dummy variable trap); what is the $R^2$ and `RMSE` on the test set? Which model performs better on the test set? Make a third model that combines all the regressors from the previous two; what is the $R^2$ and `RMSE` on the test set? Does the joint model perform better or worse, and by home much?\n",
    "  5. Use the `PolynomialFeatures` function from `sklearn` to expand the set of numerical variables you're using in the regression. As you increase the degree of the expansion, how do the $R^2$ and `RMSE` change? At what point does $R^2$ go negative on the test set? For your best model with expanded features, what is the $R^2$ and `RMSE`? How does it compare to your best model from part 4?\n",
    "  6. For your best model so far, determine the predicted values for the test data and plot them against the true values. Do the predicted values and true values roughly line up along the diagonal, or not? Compute the residuals/errors for the test data and create a kernel density plot. Do the residuals look roughly bell-shaped around zero? Evaluate the strengths and weaknesses of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a",
   "metadata": {
    "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a"
   },
   "source": [
    "**Q3.** This is a question about linear regression. The outcome is whether a defendant is held pre-trial in the Virginia justice system. We would like to understand how that outcome is predicted by characteristics of the defendant, particularly race. Let's be very careful/clear: We aren't saying anyone *should* be held without bond or asserting that people with different demographic variables *should* be more likely to be held, but instead trying to predict whether people with different characteristics *are empirically more likely* to be held without bond, given the available information. This is the first step we would take in investigating whether a system is fair, or how large the disparities are: Does it treat people with similar observable characteristics similarly, or not? We are going to look at a common question: Are Black defendants treated differently from white or Asian ones? (There are Native American defendants, but there are 11 in total, which is such a small number of observations that is difficult to clearly say anything about how this group is treated relative to the others.)\n",
    "\n",
    "The variables in the data are:\n",
    "\n",
    "  - `held_wo_bail`: Whether a defendant is held without bail before trial (Boolean logical)\n",
    "  - `race`, `sex`: Categorical demographic variables\n",
    "  - `is_poor`: Whether the defendant is classified as indigent\n",
    "  - `prior_F`, `prior_M`: The number of prior felony and misdemeanor arrests\n",
    "  - `case_type`: A categorical variable indicating a misdemeanor `M` or felony `F` or infraction `I` or special case `S`\n",
    "  - `age`: Defendant's age\n",
    "  - `bond`, `bond_NA`, `bond_type`: The amount of any bond, whether it is missing, and the type\n",
    "  - `sentence`, `sentence_NA`, `sentence_type`: The length of any sentence, whether it is missing, and the type\n",
    "\n",
    "1. Load the `pretrial_data.csv` data. Notice that there are `nan`s, but the data are relatively clean. Because there are `.nan`s among variables you won't use, you'll want to narrow down your analysis to the relevant variables before dropping or imputing missing values.\n",
    "2. Create a dummy variable indicating that the defendant is Black.\n",
    "3. Regress `held` on `Black`. What is the slope coefficient Interpret the coefficient on the Black dummy variable: How much more likely is a black person to be held without bail? What is the $R^2$ of the model?\n",
    "4. Before doing this question, please think for a few minutes about how to make the process of running the following regressions as efficient as possible, before jumping into writing code. Repeat part 2, for the following specifications, keeping track of the coefficient on the Black dummy variable each time:\n",
    "      - `held` on `Black` and `sex`\n",
    "      - `held` on `Black` and `sex` and `is_poor`\n",
    "      - `held` on `Black` and `sex` and `is_poor` and `prior_F`\n",
    "      - `held` on `Black` and `sex` and `is_poor` and `prior_F` and `case_type`\n",
    "What happens to the coefficient on the Black dummy variable as you include more regressors/features/controls in the regression? Explain your findings.\n",
    "5. Suppose we don't want to see just `Black` and `sex`, but `Black` interacted with `sex`: Are Black men and Black women treated systemically differently from the rest of the population? Implement this in a regression, and explain your findings.\n",
    "6. Imagine someone argued we should use these kinds of models to help a judge or magistrate make bail decisions (you could obviously go back and make this kind of model for the bond and sentence variables, then deploy it on new cases to predict what their bond and sentence values would be). What concerns would you have? Do you think society should be using data-driven and automated tools like that? Explain your concerns clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bedb79-b3d9-4db3-9b30-b92c9b618cec",
   "metadata": {
    "id": "d0bedb79-b3d9-4db3-9b30-b92c9b618cec"
   },
   "source": [
    "**Q4.** This is a math question to review the derivation of the OLS estimator (but only if you are into that kind of thing!). We are going to do it slightly differently from what we did in class, though. We will use a linear predictor and minimize the Sum of Squared Errors, just as in class. But, we are going to de-mean $X$ first, creating another variable $z_i = x_i - \\bar{x}$ where\n",
    "$$\n",
    "\\bar{x} = \\dfrac{1}{N} \\sum_{i=1}^N x_i,\n",
    "$$\n",
    "so the model is $\\hat{y}_i = a + b z_i$ and the `SSE` is\n",
    "$$\n",
    "\\text{SSE}(a,b) = \\sum_{i=1}^N (y_i - a - bz_i)^2.\n",
    "$$\n",
    "\n",
    "  1. Take partial derivatives of the `SSE` with respect to $a$ and $b$. You should get\n",
    "\n",
    "\\begin{alignat*}{3}\n",
    "\\sum_{i=1}^N -2(y_i - a- bz_i) &=& 0 \\\\\n",
    "\\sum_{i=1}^N -2(y_i - a - bz_i)z_i &=& 0.\n",
    "\\end{alignat*}\n",
    "\n",
    "  2. Solve for the solutions to the above equations. Big hint: $\\bar{z} = 0$, since we subtracted the mean of $x$ from $x$ to get $z$. You should get\n",
    "\n",
    "\\begin{alignat*}{3}\n",
    "a^* &=& \\bar{y} \\\\\n",
    "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})z_i}{\\sum_{i=1}^N z_i^2}.\n",
    "\\end{alignat*}\n",
    "\n",
    "  3. Substitute $z_i = x_i - \\bar{x}$ back into the above equations. You should get\n",
    "  \n",
    "\\begin{alignat*}{3}\n",
    "a^* &=& \\bar{y} \\\\\n",
    "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^N (x_i-\\bar{x})^2},\n",
    "\\end{alignat*}\n",
    "\n",
    "which can be written in terms of sample covariance and sample variance as:\n",
    "\n",
    "\\begin{alignat*}{3}\n",
    "a^* &=& \\bar{y} \\\\\n",
    "b^* &=& \\dfrac{\\text{cov}(x,y)}{\\text{var}(x)}.\n",
    "\\end{alignat*}\n",
    "\n",
    "This is typically the preferred way of expressing the OLS coefficients.\n",
    "\n",
    "4. When will $b^*$ be large or small, depending on the relationship between $x$ and $y$ and the amount of \"noise\"/variance in $x$? What does $a^*$ represent?\n",
    "5. Suppose you have measurement error in $x$ which artificially inflates its variance (e.g. bad data cleaning). What happens to the $b^*$ coefficient? How will affect your ability to predict? (This phenomenon is called **attenuation**.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67478ac-ad78-4a44-9720-583c71b8da14",
   "metadata": {
    "id": "b67478ac-ad78-4a44-9720-583c71b8da14"
   },
   "source": [
    "**Q5.**\n",
    "1. Find a dataset on a topic you're interested in. Some easy options are data.gov, kaggle.com, and data.world.\n",
    "2. Clean the data and do some exploratory data analysis on key variables that interest you. Pick a particular target/outcome variable and features/predictors.\n",
    "3. Split the sample into an ~80% training set and a ~20% test set.\n",
    "4. Run a few regressions of your target/outcome variable on a variety of features/predictors. Compute the SSE on the test set.\n",
    "5. Which model performed the best, and why?\n",
    "6. What did you learn?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
